## 2.4 分类器，判别函数和决策面

### 2.4.1 多分类的情况

最常用的模式分类表达式为，用判别函数 gi(**x**)，i = 1,...,c。
分类器会根据观测值 **x** 分成 wi 如果：
gi(**x**) > gj(**x**) 对于所有 j != i 都成立。

因此分类器的结构像图2.5所示。分类器会计算 c 个判别函数并选择结果最大的那个类别。

![图2.5](https://yg-1255660153.cos.ap-chengdu.myqcloud.com/PatternClassification/F02.05.jpg)
> 图2.5

贝叶斯分类器也很容易用这种形式表示，我们设 gi(**x**) = -R(αi|**x**) 即可。而对于最小化错误率的情况，设定 gi(**x**) = P(wi|**x**) 即可。

更一般地，我们使用一个单调递增函数 f(.) 代替每个 gi(**x**) 得到 f(gi(**x**))。这样的分类结果仍与原来一致，并且对于数学分析和计算简化也有所帮助。实际上，对于最小化错误率分类而言，有多种计算公式都是可行的，但是有些更易理解并容易计算。

尽管判别函数有多种写法，但是最终的决策结果都是等价的。我们的决策规则会把整个特征空间分成 c 个决策区域，R1，...，Rc。如果有 gi(**x**) > gj(**x**) 对于所有的 j != i 都成立，那么观测值 **x** 的结果就会落在 Ri 中，于是决策规则会告诉我们选择 wi。决策区域被决策边界分离开来，它们是特征空间的一些面，如图2.6所示。

![图2.6](https://yg-1255660153.cos.ap-chengdu.myqcloud.com/PatternClassification/F02.06.jpg)
> 图2.6

### 2.4.2 二分类的情况

二分类属于多分类的特殊情况，它也有专门的名字：二分器。对于二分类而言，通常使用一个函数即可定义：
g(**x**) ≡ g1(**x**) - g2(**x**)。
当 g(**x**) > 0 时选择 w1，否则选择 w2。比如有以下两种常用形式：
g(**x**) = P(w1|**x**) - P(w2|**x**)
g(**x**) = ln(p(**x**|w1) / p(**x**|w2)) + ln(P(w1) / P(w2))